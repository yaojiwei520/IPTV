name: Update IPTV Sources

on:
  schedule:
    # Runs every 15 minutes
    # For example, at XX:00, XX:15, XX:30, XX:45 (UTC time)
    - cron: '*/15 * * * *'
  workflow_dispatch: # Allows manual triggering from GitHub UI

jobs:
  update-and-clean:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Fetch all history to allow `add-and-commit` to work correctly
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Fetch and Clean IPTV data
        id: fetch_clean_data
        run: |
          SOURCE_URL="https://raw.githubusercontent.com/hujingguang/ChinaIPTV/main/cnTV_AutoUpdate.m3u8"
          CLEANED_FILE="cnTV_AutoUpdate.m3u"
          RAW_FILE="raw_source.m3u8"

          echo "Step 1: Fetching raw data from $SOURCE_URL..."
          curl -s "$SOURCE_URL" > "$RAW_FILE"

          if [ ! -f "$RAW_FILE" ] || [ ! -s "$RAW_FILE" ]; then
              echo "Error: Failed to download source file or '$RAW_FILE' is empty."
              exit 1
          fi

          echo "Step 2: Cleaning the data..."
          python -c \
          "import re

          output_lines = []
          try:
              with open('$RAW_FILE', 'r', encoding='utf-8') as f_in:
                  lines = f_in.readlines()
                  i = 0
                  while i < len(lines):
                      line = lines[i].strip()
                      if line.startswith('#EXTINF:'):
                          output_lines.append(line)
                          # Check if the next line is a URL
                          if i + 1 < len(lines):
                              next_line = lines[i+1].strip()
                              if next_line.startswith('http://') or next_line.startswith('https://'):
                                  output_lines.append(next_line)
                                  i += 1 # Skip the URL line as it's already processed
                      i += 1
          except Exception as e:
              print(f'Error reading or processing raw file: {e}')
              exit(1)

          with open('$CLEANED_FILE', 'w', encoding='utf-8') as f_out:
              f_out.write('#EXTM3U\n') # Add the M3U header
              for line in output_lines:
                  f_out.write(line + '\n')
          "
          echo "Cleaned data saved to $CLEANED_FILE"

      - name: Merge cleaned data with iptv.m3u and deduplicate
        run: |
          MERGED_FILE="iptv.m3u"
          CLEANED_FILE="cnTV_AutoUpdate.m3u"

          # Ensure iptv.m3u exists, initialize if not
          if [ ! -f "$MERGED_FILE" ]; then
              echo '#EXTM3U' > "$MERGED_FILE"
          fi

          # Append cleaned data to iptv.m3u, avoiding duplicate #EXTM3U header from cleaned file
          # Use awk to skip the first line (#EXTM3U) of cnTV_AutoUpdate.m3u if it exists
          awk 'NR > 1 || !/^#EXTM3U$/' "$CLEANED_FILE" >> "$MERGED_FILE"

          echo "Merging completed. Now deduplicating $MERGED_FILE..."
          # Deduplicate iptv.m3u in place
          python -c \
          "import re
          seen_entries = set()
          output_lines = ['#EXTM3U'] # Always start with one #EXTM3U header

          try:
              with open('$MERGED_FILE', 'r', encoding='utf-8') as f_in:
                  lines = f_in.readlines()
                  i = 0
                  while i < len(lines):
                      line = lines[i].strip()
                      # Ignore empty lines
                      if not line:
                           i += 1
                           continue
                      
                      # Only process #EXTINF and its associated URL
                      if line.startswith('#EXTINF:'):
                          if i + 1 < len(lines):
                              next_line = lines[i+1].strip()
                              if next_line.startswith('http://') or next_line.startswith('https://'):
                                  # Create a unique key for the channel entry (EXTINF + URL)
                                  entry_key = (line, next_line)
                                  if entry_key not in seen_entries:
                                      seen_entries.add(entry_key)
                                      output_lines.append(line)
                                      output_lines.append(next_line
                                  i += 1 # Skip the URL line since it's part of this entry
                          else:
                              # If #EXTINF is the last line or not followed by a URL, still add it
                              # (though this should ideally not happen in valid m3u)
                              entry_key = (line, '') # Use empty string for URL if none
                              if entry_key not in seen_entries:
                                  seen_entries.add(entry_key)
                                  output_lines.append(line)
                      elif line == '#EXTM3U': # Skip subsequent #EXTM3U headers
                          pass
                      elif line.startswith('http://') or line.startswith('https://'): # Handle loose URLs without #EXTINF
                          entry_key = ('', line) # Treat as a standalone URL
                          if entry_key not in seen_entries:
                              seen_entries.add(entry_key)
                              output_lines.append(line)
                      
                      i += 1
          except Exception as e:
              print(f'Error deduplicating file: {e}')
              exit(1)

          with open('$MERGED_FILE', 'w', encoding='utf-8') as f_out:
              f_out.write('\\n'.join(output_lines) + '\\n')
          "
          echo "Deduplication completed for $MERGED_FILE"


      - name: Update VersionLog
        run: |
          LOG_FILE="VersionLog.md"
          # Ensure VersionLog.md exists
          if [ ! -f "$LOG_FILE" ]; then
              echo "# Update Log" > "$LOG_FILE"
          fi
          # Append new log entry
          # GITHUB_REF_NAME provides branch name, or 'manual-run' for workflow_dispatch
          echo "## ${GITHUB_REF_NAME:-Manual Run} - Update on $(TZ='Asia/Shanghai' date '+%Y-%m-%d %H:%M:%S %Z')" >> "$LOG_FILE"
          echo "" >> "$LOG_FILE" # Add an empty line for better readability

      - name: Commit and push changes
        uses: EndBug/add-and-commit@v9
        with:
          # Specify files to add/commit. Ensure 'raw_source.m3u8' is NOT committed.
          add: 'cnTV_AutoUpdate.m3u iptv.m3u VersionLog.md'
          message: 'Auto-update IPTV sources and log [skip ci]'
          default_author: github_actions
          # The GITHUB_TOKEN has permissions to push to the repository
          # It's automatically provided by GitHub Actions
          token: ${{ secrets.GITHUB_TOKEN }}
